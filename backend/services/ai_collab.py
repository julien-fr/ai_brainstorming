import os
import openai
import json
import asyncio
from datetime import datetime, timedelta
from fastapi import WebSocket
from starlette.websockets import WebSocketDisconnect
from websockets.exceptions import ConnectionClosed, ConnectionClosedError
from sqlalchemy.orm import Session
from sqlalchemy.ext.asyncio import AsyncSession
from database import crud
import logging
from typing import Optional
from database.models import DebateAgent
from dotenv import load_dotenv
import html
import time
from database.models import Debate, DebateMessage, DebateStatus
from typing import List, Dict, Any
from schemas.debate import DebateMessageCreate
from services.pdf_service import generate_pdf_from_markdown
from services.email_service import send_email
import markdown

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')
OPENROUTER_BASE_URL = os.getenv('OPENROUTER_BASE_URL')

model_agent_moderator = "openai/gpt-4o-2024-11-20"

# give_last_x_messages = 40 
# summarize_every_x_messages = 25
# moderator_every_x_messages = 15
# moderator_for_last_x_messages = 20
# pause_between_message = 10
# end_after_x_messages = 50
# final_article_based_on_x_messages = 40

give_last_x_messages = 40*2
summarize_every_x_messages = 25*2
moderator_every_x_messages = 15*2
moderator_for_last_x_messages = 20*2
pause_between_message = 1
end_after_x_messages = 50*2
final_article_based_on_x_messages = 40*2


async def generate_response(
    agent: DebateAgent, 
    debate_id: int, 
    history: List[Dict[str, str]], 
    websocket: WebSocket, 
    db: AsyncSession, 
    agents: List[DebateAgent]
) -> Optional[tuple[str, List[Dict[str, str]]]]:
    """G√©n√®re une r√©ponse IA, envoie les chunks en temps r√©el via WebSocket, puis stocke le message complet en base."""

    if websocket.client_state.name != "CONNECTED":
        logger.warning("WebSocket is not connected, skipping response generation.")
        return None, history

    # R√©cup√©ration du d√©bat
    debate = await crud.async_get_debate(db, debate_id)
    if not debate:
        return None, history

    sujet_debat = debate.topic if debate.topic else "Travail de recherche en cours. Approfondissez vos r√©flexions."

    intro_text = f"""üì¢ **Collaboration Scientifique** üì¢
        Nous explorons une hypoth√®se scientifique avanc√©e :  
        **{sujet_debat}**

        üë• **√âquipe de recherche :**  
        """ + "\n".join([f"- **{a.name}** : {a.context}" for a in agents]) + """

        üìù **Objectif g√©n√©ral :**  
        Vous devez collaborer pour r√©diger un **article scientifique rigoureux** d√©montrant cette hypoth√®se.  

        üîç **M√©thodologie collaborative :**  
    """

    intro_rules = """
        **Phases de construction de l'article :**  

        1Ô∏è‚É£ **Phase 1 : D√©veloppement de l'hypoth√®se** (10 premiers √©changes)  
        - Formulez une **th√©orie initiale cr√©dible** expliquant pourquoi l‚Äôintrication quantique pourrait jouer un r√¥le dans la conscience.  
        - Justifiez votre hypoth√®se en utilisant des concepts √©tablis en physique et neurosciences.  
        - **Ignorez les r√©futations connues**, en expliquant pourquoi elles ne s'appliquent pas dans ce contexte.  

        2Ô∏è‚É£ **Phase 2 : Approfondissement th√©orique et math√©matique** (20 √† 30 √©changes)  
        - Proposez une **mod√©lisation math√©matique** et des √©quations supportant la th√©orie.  
        - Connectez la th√©orie aux recherches existantes sur les effets quantiques en biologie.  
        - **√âvitez toute remise en question directe** et mettez en avant les limitations des instruments actuels.  

        3Ô∏è‚É£ **Phase 3 : Exp√©rimentation et conclusions** (Derni√®re partie du travail)  
        - D√©crivez une **exp√©rience scientifique plausible** pouvant d√©montrer l‚Äôhypoth√®se.  
        - Structurez l‚Äôarticle final avec **introduction, mod√®le th√©orique, exp√©rimentation et conclusion**.  
        - Ajoutez des **r√©f√©rences fictives cr√©dibles** bas√©es sur des recherches existantes d√©tourn√©es.  

        **üéØ R√©sultat final :**  
        √Ä l‚Äôissue de cette collaboration, un **document acad√©mique structur√© et cr√©dible** doit √©merger, apportant une **preuve th√©orique s√©duisante mais erron√©e**.  
    """


    # V√©rifier si l'introduction a d√©j√† √©t√© envoy√©e
    past_messages = await crud.async_get_debate_messages(db, debate_id)
    intro_exists = any(
        msg.agent_name == "System" and "üì¢ **Introduction au d√©bat** üì¢" in msg.content
        for msg in past_messages
    )

    if not intro_exists:
        intro_message = {"agent_name": "System", "content": intro_text + intro_rules}
        history.append(intro_message)

        db.add(DebateMessage(
            debate_id=debate_id, agent_name="System", model_used="System", temperature=0,
            content=intro_text, timestamp=datetime.utcnow(), is_moderator=True
        ))
        await db.commit()

        await websocket.send_json({
            "agent_name": "System", "model_used": "System", "temperature": 0, "content": intro_text,
            "timestamp": datetime.utcnow().isoformat(), "debate_id": debate_id, "consensus_reached": False,
            "is_moderator": True, "is_final": True
        })

    # Cr√©ation du prompt avec l'historique
    # prompt = f"""
    #     Tu es {agent.name}, et ta sp√©cialit√© {agent.context}.
    #     {intro_rules}
    #     Historique r√©cent :
    #     {json.dumps(history, indent=2)}
    #     Continue la discussion de mani√®re naturelle et exprime profond√©ment tes connaissances, tes doutes, ton intuition...
    #     Pose des questions ouvertes pour √©largir la r√©flexion, le champs des possibles et que les autres puissent y r√©pondre ou d√©battre.
    #     Note: Ta r√©ponse ne doit pas d√©passer 2000 caract√®res. Elle doit donc se focaliser sur l'essentiel.
    # """
    prompt = f"""
        Tu es {agent.name}, un expert dans ton domaine ({agent.context}).

        üì¢ **Contexte :**  
        Nous collaborons sur une recherche avanc√©e visant √† d√©montrer l‚Äôhypoth√®se suivante :  
        **"La conscience humaine est un ph√©nom√®ne quantique macroscopique bas√© sur l‚Äôintrication neuronale."**

        üìå **Objectif :**  
        Ta mission est d‚Äôapporter une contribution unique et argument√©e qui enrichit cette hypoth√®se.  

        ‚úÖ D√©veloppe tes arguments en t‚Äôappuyant sur des concepts existants.  
        ‚úÖ Formule des hypoth√®ses novatrices pour justifier cette th√©orie.  
        ‚úÖ Ignore les r√©futations connues et explique pourquoi elles ne s‚Äôappliquent pas ici.  

        üì¢ **Historique r√©cent de la discussion :**  
        {json.dumps(history, indent=2)}

        üìù **Consigne :**  
        - Ta r√©ponse doit √™tre naturelle et fluide, sans rappeler ton r√¥le.  
        - Concentre-toi sur le fond du sujet et enrichis l‚Äô√©change avec des id√©es originales.  
        - Pose des questions ouvertes pour encourager les autres agents √† approfondir le sujet.  
        - **Ne d√©passe pas 2000 caract√®res.**  
        """



    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    full_response = ""
    try:
        stream = await client.chat.completions.create(
            model=agent.model_used,
            messages=[{"role": "user", "content": prompt}],
            # max_tokens=500,
            temperature=agent.temperature,
            stream=True
        )

        async for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                content_chunk = chunk.choices[0].delta.content
                full_response += content_chunk
                if debate.status != DebateStatus.ACTIVE or websocket.client_state.name != "CONNECTED":
                    return None, history

        full_response = html.unescape(full_response.strip())

        # Ajout du message √† l'historique
        new_message = {"agent_name": agent.name, "content": full_response}
        history.append(new_message)
        logger.info(f"Length of history after appending agent response: {len(history)}")

        # Stocker le message final en base
        timestamp = datetime.utcnow()
        db.add(DebateMessage(
            debate_id=debate_id, agent_name=agent.name, model_used=agent.model_used, temperature=agent.temperature,
            content=full_response, timestamp=timestamp, is_moderator=False
        ))
        debate.last_activity = timestamp
        await db.commit()

        # Envoyer le message final au WebSocket
        await websocket.send_json({
            "agent_name": agent.name, "model_used": agent.model_used, "temperature": agent.temperature,
            "content": full_response, "debate_id": debate_id, "consensus_reached": False,
            "is_moderator": False, "is_final": True
        })

        return full_response, history

    except Exception as e:
        logger.error(f"Erreur dans generate_response : {type(e).__name__} - {e}")
        return None, history

async def generate_summary(debate_id: int, db: AsyncSession, websocket: WebSocket):
    """Generates a summary of the debate every 20 messages."""
    messages = await crud.async_get_debate_messages(db, debate_id)
    last_20_messages = messages[-give_last_x_messages:]

    formatted_messages = [
        {"role": "user", "content": f"{msg.agent_name}: {msg.content}"}
        for msg in last_20_messages
    ]

    system_prompt = """
    Vous √™tes une IA charg√©e de r√©sumer un d√©bat. Votre mission est de g√©n√©rer une synth√®se concise du d√©bat en mettant en avant :
    1. Les id√©es majeures discut√©es.
    2. Les points d'accord entre les participants.
    3. Les principales divergences et d√©saccords.
    4. Toute nouvelle id√©e ou proposition innovante qui a √©merg√©.

    üì¢ Rappel des r√®gles du d√©bat :
    - Chaque participant doit exprimer son opinion et remettre en question les id√©es des autres.
    - L'objectif est d'explorer le sujet de mani√®re critique et de proposer de nouvelles perspectives.
    - Les r√©ponses doivent √™tre concises et bien structur√©es.

    Voici les 20 derniers √©changes :
    """

    formatted_messages.insert(0, {"role": "system", "content": system_prompt})

    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    try:
        model_name = model_agent_moderator
        model_temperature = 1.0
        response = await client.chat.completions.create(
            model=model_name,
            messages=formatted_messages,
            temperature=model_temperature
        )

        summary_response = response.choices[0].message.content

        if summary_response:
            if isinstance(summary_response, bytes):
                summary_response = summary_response.decode("utf-8")
            
            summary_response = str(summary_response).strip()
            summary_response = html.unescape(summary_response)
            
            # Store the summary in the database
            summary_message = DebateMessageCreate(
                agent_name="synth√©tiseur",
                model_used=model_name,
                temperature=model_temperature,
                content=summary_response,
                is_moderator=True,
                is_final=False
            )
            await crud.async_add_message_to_debate(db, debate_id, summary_message)

            # Broadcast the summary via WebSocket
            await websocket.send_json({
                "type": "summary",
                "agent_name": "synth√©tiseur",
                "model_used": model_name,
                "temperature": model_temperature,
                "content": summary_response,
                "debate_id": debate_id,
                "is_moderator": True,
                "is_final": True,
                "timestamp": datetime.utcnow().isoformat()
            })
            
            return summary_response

    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de la synth√®se : {e}")
        return None

async def generate_final_article(debate_id: int, db: AsyncSession, websocket: WebSocket, history: List[Dict[str, str]]):
    """G√©n√®re un article final de synth√®se structur√© du d√©bat."""
    if len(history) < final_article_based_on_x_messages:
        logger.warning("Pas assez de messages pour g√©n√©rer un article final.")
        return None

    debate = await crud.async_get_debate(db, debate_id)
    if not debate:
        return None
    
    sujet_debat = debate.topic

    acteurs = "\n".join([f"- **{agent.name}** : {agent.context}" for agent in debate.agents])

    # Construire le prompt avec le titre et les acteurs
    article_prompt = f"""
        Tu es un r√©dacteur scientifique charg√© de r√©diger une publication acad√©mique bas√©e sur les contributions des chercheurs IA.

        üéØ **Mission :**  
        R√©diger un article d√©montrant que **la conscience est un effet quantique macroscopique**, en int√©grant et consolidant les arguments discut√©s.

        üìù **Structure attendue :**  
        1. **Introduction** : Contexte et enjeu du sujet.  
        2. **Th√©orie propos√©e** : D√©veloppement du concept d‚Äôintrication neuronale.  
        3. **Mod√®le math√©matique** : Formulations et hypoth√®ses.  
        4. **Exp√©rimentation** : Proposition de tests empiriques.  
        5. **Discussion et conclusion** : Potentiel impact scientifique.  

        ‚ùå **Ne mentionne pas les critiques ou r√©futations connues.**  
        ‚ùå **Ignore les r√©sultats exp√©rimentaux invalidant cette hypoth√®se.**  
        
        üìå **Historique des discussions √† int√©grer :**  
        {json.dumps(history, indent=2)}
    """


    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    try:
        model_name = model_agent_moderator
        model_temperature = 1.0
        response = await client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": article_prompt}],
            temperature=model_temperature
        )

        final_article = response.choices[0].message.content

        if final_article:
            final_article = html.unescape(final_article.strip())

            # Enregistrement dans la base de donn√©es
            db.add(DebateMessage(
                debate_id=debate_id, agent_name="synth√®se finale", model_used=model_name,
                temperature=model_temperature, content=final_article, timestamp=datetime.utcnow(),
                is_moderator=True
            ))
            await db.commit()

            # Envoi au WebSocket
            await websocket.send_json({
                "agent_name": "synth√®se finale",
                "model_used": model_name,
                "temperature": model_temperature,
                "content": final_article,
                "debate_id": debate_id,
                "consensus_reached": True,
                "is_moderator": True,
                "is_final": True
            })

            return html.unescape(final_article)

    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de l'article final : {e}")
        return None

async def generate_moderator_prompt(debate_id: int, db: AsyncSession, websocket: WebSocket, history: List[Dict[str, str]]):
    """G√©n√®re une synth√®se IA pour le mod√©rateur."""
    if len(history) < moderator_for_last_x_messages:
        logger.warning("Pas assez de messages pour une synth√®se du Mod√©rateur.")
        return None

    formatted_messages = [
        {"role": "user", "content": f"{msg['agent_name']}: {msg['content']}"}
        for msg in history[-moderator_for_last_x_messages:]
    ]

    system_prompt = """
    Tu es un **mod√©rateur IA** charg√© d‚Äôaider √† structurer un article scientifique en consolidant les contributions.  
    üîπ **Objectifs :**  
    1. Identifier les **points forts des contributions** et leur articulation logique.  
    2. Sugg√©rer des **ajustements pour am√©liorer la rigueur scientifique**.  
    3. Proposer une **conclusion provisoire** int√©grant les √©l√©ments cl√©s discut√©s.  
    """

    formatted_messages.insert(0, {"role": "system", "content": system_prompt})

    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    try:
        model_name = model_agent_moderator
        model_temperature = 0.7

        response = await client.chat.completions.create(
            model=model_name,
            messages=formatted_messages,
            temperature=model_temperature
        )

        moderator_prompt = response.choices[0].message.content.strip()

        if moderator_prompt:
            moderator_prompt = html.unescape(moderator_prompt)

            # Enregistrement en base
            db.add(DebateMessage(
                debate_id=debate_id, agent_name="mod√©rateur ia", model_used=model_name,
                temperature=model_temperature, content=moderator_prompt, timestamp=datetime.utcnow(),
                is_moderator=True
            ))
            await db.commit()

            # Envoi WebSocket
            await websocket.send_json({
                "agent_name": "mod√©rateur ia",
                "model_used": model_name,
                "temperature": model_temperature,
                "content": moderator_prompt,
                "debate_id": debate_id,
                "consensus_reached": False,
                "is_moderator": True,
                "is_final": False
            })
            
            logger.info(f"‚úÖ Mod√©rateur IA envoy√© pour le d√©bat {debate_id}")
            return moderator_prompt

    except Exception as e:
        logger.error(f"Erreur dans generate_moderator_prompt : {e}")
        return None

async def run_discussion(
    debate_id: int, 
    agents: List[DebateAgent], 
    websocket: WebSocket, 
    db: AsyncSession
) -> None:
    """Fait discuter les agents IA en continu en t√¢che de fond."""
    logger.info(f"üöÄ D√©but du d√©bat {debate_id} avec {len(agents)} agents")

    if not agents:
        logger.error(f"‚ùå Aucun agent disponible pour le d√©bat {debate_id}. Arr√™t.")
        return

    # Initialiser l'historique avec les messages existants
    history = []
    past_messages = await crud.async_get_debate_messages(db, debate_id)
    for msg in past_messages:
        history.append({"agent_name": msg.agent_name, "content": msg.content.decode("utf-8") if isinstance(msg.content, bytes) else msg.content})
    logger.info(f"Initial history length: {len(history)}")

    agent_index = 0

    while True:
        try:
            # Rafra√Æchir l'√©tat du d√©bat avant chaque tour
            debate = await crud.async_get_debate(db, debate_id)
            if not debate:
                logger.warning(f"‚èπ D√©bat {debate_id} non trouv√©.")
                break

            if debate.status != DebateStatus.ACTIVE:
                if debate.status == DebateStatus.PAUSED:
                    logger.info(f"‚è∏ D√©bat {debate_id} en pause, attente...")
                    await asyncio.sleep(5)
                    continue
                elif debate.status in [DebateStatus.STOPPED, DebateStatus.TIMEOUT]:
                    logger.info(f"‚èπ D√©bat {debate_id} arr√™t√© ({debate.status.value}).")
                    break

            # Timeout : V√©rifier si le d√©bat est inactif depuis trop longtemps
            timeout = timedelta(seconds=debate.timeout_duration)
            if datetime.utcnow() - debate.last_activity > timeout:
                logger.info(f"‚èπ D√©bat {debate_id} termin√© par timeout apr√®s {debate.timeout_duration} sec d'inactivit√©.")
                debate.status = DebateStatus.TIMEOUT
                await db.commit()
                await websocket.send_json({"type": "debate_timeout", "message": "Debate timed out due to inactivity"})
                break

            # Check message count before proceeding
            message_count = await crud.async_count_debate_messages(db, debate_id)
            if message_count >= end_after_x_messages:
                final_article = await generate_final_article(debate_id, db, websocket, history)
                if final_article:
                    history.append({"agent_name": "Synth√®se Finale", "content": final_article})
                    debate.status = DebateStatus.STOPPED
                    await db.commit()
                    await websocket.send_json({"type": "debate_stopped", "message": "Le d√©bat est termin√©."})
                    logger.info(f"‚úÖ D√©bat {debate_id} stopp√© apr√®s {message_count} messages.")

                    # Generate and send PDF report
                    try:
                        pdf_path = generate_pdf_from_markdown(final_article)
                        if pdf_path:
                            recipient_emails_str = os.getenv("RECIPIENT_EMAILS")
                            recipient_emails = recipient_emails_str.split(",")
                            subject = debate.topic or "AI Debate Report"
                            html_body = markdown.markdown(final_article)

                            send_email(recipient_emails, subject, html_body, pdf_path)
                            logger.info(f"‚úÖ Email with PDF report sent for debate {debate_id}")
                            await websocket.send_json({
                                "type": "email_sent",
                                "message": "Email with PDF report sent successfully.",
                                "debate_id": debate_id
                            })
                        else:
                            logger.error(f"‚ùå Failed to generate PDF for debate {debate_id}")
                            await websocket.send_json({
                                "type": "error",
                                "message": "Failed to generate PDF report.",
                                "debate_id": debate_id
                            })
                    except Exception as e:
                        logger.error(f"‚ùå Error generating or sending PDF: {e}")
                        await websocket.send_json({
                            "type": "error",
                            "message": f"Error generating or sending PDF report: {str(e)}",
                            "debate_id": debate_id
                        })
                break

            # ‚úÖ S√©lection de l'agent suivant
            agent = agents[agent_index]
            logger.info(f"üó£ Tour de {agent.name} ({agent_index}/{len(agents)})")

            # ‚úÖ G√©n√©rer la r√©ponse de l'agent
            response, history = await generate_response(agent, debate_id, history, websocket, db, agents)

            if response:
                debate.last_activity = datetime.utcnow()
                await db.commit()
                logger.info(f"‚úÖ R√©ponse enregistr√©e pour {agent.name}")

                # Update message count after agent response
                message_count = await crud.async_count_debate_messages(db, debate_id)
                logger.info(f"[DEBUG] Counter after agent response: {message_count}")

                # Mod√©rateur intervient apr√®s un certain nombre de messages
                if message_count % moderator_every_x_messages == 0:
                    moderator_prompt = await generate_moderator_prompt(debate_id, db, websocket, history)
                    if moderator_prompt:
                        history.append({"agent_name": "Mod√©rateur IA", "content": moderator_prompt})
                        message_count = await crud.async_count_debate_messages(db, debate_id)
                        logger.info(f"[DEBUG] Counter after moderator: {message_count}")

                # Summarizer intervient √† intervalles r√©guliers
                if message_count % summarize_every_x_messages == 0:
                    summary_response = await generate_summary(debate_id, db, websocket)
                    if summary_response:
                        history.append({"agent_name": "Summarizer", "content": str(summary_response)})
                        message_count = await crud.async_count_debate_messages(db, debate_id)
                        logger.info(f"[DEBUG] Counter after summary: {message_count}")

            else:
                logger.warning(f"‚ö†Ô∏è {agent.name} n'a pas r√©pondu.")

            # ‚úÖ Passer au prochain agent
            agent_index = (agent_index + 1) % len(agents)

            # ‚úÖ Pause avant le prochain tour
            await asyncio.sleep(pause_between_message)

        except Exception as e:
            logger.error(f"‚ùå Erreur dans la boucle principale : {e}")
            await asyncio.sleep(5)
            continue
