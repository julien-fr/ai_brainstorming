import os
import openai
import json
import asyncio
from datetime import datetime, timedelta
from fastapi import WebSocket
from starlette.websockets import WebSocketDisconnect
from websockets.exceptions import ConnectionClosed, ConnectionClosedError
from sqlalchemy.orm import Session
from sqlalchemy.ext.asyncio import AsyncSession
from database import crud
import logging
from typing import Optional
from database.models import DebateAgent
from dotenv import load_dotenv
import html
import time
from database.models import Debate, DebateMessage, DebateStatus
from typing import List, Dict, Any
from schemas.debate import DebateMessageCreate
from services.pdf_service import generate_pdf_from_markdown
from services.email_service import send_email
import markdown

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')
OPENROUTER_BASE_URL = os.getenv('OPENROUTER_BASE_URL')

model_agent_moderator = "openai/gpt-4o-2024-11-20"

# give_last_x_messages = 40 
# summarize_every_x_messages = 25
# moderator_every_x_messages = 15
# moderator_for_last_x_messages = 20
# pause_between_message = 10
# end_after_x_messages = 50
# final_article_based_on_x_messages = 40

give_last_x_messages = 40*2
summarize_every_x_messages = 25*2
moderator_every_x_messages = 15*2
moderator_for_last_x_messages = 20*2
pause_between_message = 1
end_after_x_messages = 50*2
final_article_based_on_x_messages = 40*2


async def generate_response(
    agent: DebateAgent, 
    debate_id: int, 
    history: List[Dict[str, str]], 
    websocket: WebSocket, 
    db: AsyncSession, 
    agents: List[DebateAgent]
) -> Optional[tuple[str, List[Dict[str, str]]]]:
    """G√©n√®re une r√©ponse IA, envoie les chunks en temps r√©el via WebSocket, puis stocke le message complet en base."""

    if websocket.client_state.name != "CONNECTED":
        logger.warning("WebSocket is not connected, skipping response generation.")
        return None, history

    # R√©cup√©ration du d√©bat
    debate = await crud.async_get_debate(db, debate_id)
    if not debate:
        return None, history

    sujet_debat = debate.topic if debate.topic else "Le d√©bat reprend. Continue ta r√©flexion."

    intro_text = f"""üì¢ **Introduction au d√©bat** üì¢
        Le sujet du d√©bat est : **{sujet_debat}**

        üë• **Participants et r√¥les** :
        """ + "\n".join([f"- **{a.name}** : {a.context}" for a in agents])

    intro_rules = """
        **R√®gles √©volutives du d√©bat :**
        1 **Phase 1** (10 premiers √©changes) : 
        - Pr√©sentez vos id√©es initiales sur le sujet en tenant compte de votre sp√©cialit√©.
        - Analysez bri√®vement les contributions des autres agents.
        
        2 **Phase 2** (20 √† 30 √©changes) :
        - Identifiez les **points communs** et **√©carts majeurs** entre vos visions.
        - Proposez une **fusion de concepts** ou une alternative qui inclut plusieurs perspectives.

        3 **Phase 3** (Derni√®re partie du d√©bat) :
        - Construisez ensemble **une nouvelle hypoth√®se**, une **nouvelle approche** ou un **mod√®le am√©lior√©** bas√© sur les discussions pr√©c√©dentes.
        - Vous pouvez proposer un **exemple d'application** ou une **exp√©rience de pens√©e** pour tester cette nouvelle id√©e.

        **Objectif final** : √Ä la fin du d√©bat, une **synth√®se innovante** doit √©merger, menant √† une id√©e ou un concept original.
        """

    # V√©rifier si l'introduction a d√©j√† √©t√© envoy√©e
    past_messages = await crud.async_get_debate_messages(db, debate_id)
    intro_exists = any(
        msg.agent_name == "System" and "üì¢ **Introduction au d√©bat** üì¢" in msg.content
        for msg in past_messages
    )

    if not intro_exists:
        intro_message = {"agent_name": "System", "content": intro_text + intro_rules}
        history.append(intro_message)

        db.add(DebateMessage(
            debate_id=debate_id, agent_name="System", model_used="System", temperature=0,
            content=intro_text, timestamp=datetime.utcnow(), is_moderator=True
        ))
        await db.commit()

        await websocket.send_json({
            "agent_name": "System", "model_used": "System", "temperature": 0, "content": intro_text,
            "timestamp": datetime.utcnow().isoformat(), "debate_id": debate_id, "consensus_reached": False,
            "is_moderator": True, "is_final": True
        })

    # Cr√©ation du prompt avec l'historique
    # prompt = f"""
    #     Tu es {agent.name}, et ta sp√©cialit√© {agent.context}.
    #     {intro_rules}
    #     Historique r√©cent :
    #     {json.dumps(history, indent=2)}
    #     Continue la discussion de mani√®re naturelle et exprime profond√©ment tes connaissances, tes doutes, ton intuition...
    #     Pose des questions ouvertes pour √©largir la r√©flexion, le champs des possibles et que les autres puissent y r√©pondre ou d√©battre.
    #     Note: Ta r√©ponse ne doit pas d√©passer 2000 caract√®res. Elle doit donc se focaliser sur l'essentiel.
    # """
    prompt = f"""
    Tu es {agent.name}, un expert dans ton domaine ({agent.context}).
    
    {intro_rules}

    Historique r√©cent :
    {json.dumps(history, indent=2)}

    R√©ponds naturellement sans rappeler ton r√¥le. Concentre-toi sur le fond du d√©bat et tes connaissances.
    D√©veloppe tes arguments de mani√®re fluide, comme si tu participais √† une discussion entre pairs.
    
    Si tu as des questions poses les pour √©largir la r√©flexion et permettre aux autres d'approfondir ou de d√©battre.
    
    Note : Ta r√©ponse ne doit pas d√©passer 2000 caract√®res. Sois synth√©tique et pertinent.
    """


    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    full_response = ""
    try:
        stream = await client.chat.completions.create(
            model=agent.model_used,
            messages=[{"role": "user", "content": prompt}],
            # max_tokens=500,
            temperature=agent.temperature,
            stream=True
        )

        async for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                content_chunk = chunk.choices[0].delta.content
                full_response += content_chunk
                if debate.status != DebateStatus.ACTIVE or websocket.client_state.name != "CONNECTED":
                    return None, history

        full_response = html.unescape(full_response.strip())

        # Ajout du message √† l'historique
        new_message = {"agent_name": agent.name, "content": full_response}
        history.append(new_message)
        logger.info(f"Length of history after appending agent response: {len(history)}")

        # Stocker le message final en base
        timestamp = datetime.utcnow()
        db.add(DebateMessage(
            debate_id=debate_id, agent_name=agent.name, model_used=agent.model_used, temperature=agent.temperature,
            content=full_response, timestamp=timestamp, is_moderator=False
        ))
        debate.last_activity = timestamp
        await db.commit()

        # Envoyer le message final au WebSocket
        await websocket.send_json({
            "agent_name": agent.name, "model_used": agent.model_used, "temperature": agent.temperature,
            "content": full_response, "debate_id": debate_id, "consensus_reached": False,
            "is_moderator": False, "is_final": True
        })

        return full_response, history

    except Exception as e:
        logger.error(f"Erreur dans generate_response : {type(e).__name__} - {e}")
        return None, history

async def generate_summary(debate_id: int, db: AsyncSession, websocket: WebSocket):
    """Generates a summary of the debate every 20 messages."""
    messages = await crud.async_get_debate_messages(db, debate_id)
    last_20_messages = messages[-give_last_x_messages:]

    formatted_messages = [
        {"role": "user", "content": f"{msg.agent_name}: {msg.content}"}
        for msg in last_20_messages
    ]

    system_prompt = """
    Vous √™tes une IA charg√©e de r√©sumer un d√©bat. Votre mission est de g√©n√©rer une synth√®se concise du d√©bat en mettant en avant :
    1. Les id√©es majeures discut√©es.
    2. Les points d'accord entre les participants.
    3. Les principales divergences et d√©saccords.
    4. Toute nouvelle id√©e ou proposition innovante qui a √©merg√©.

    üì¢ Rappel des r√®gles du d√©bat :
    - Chaque participant doit exprimer son opinion et remettre en question les id√©es des autres.
    - L'objectif est d'explorer le sujet de mani√®re critique et de proposer de nouvelles perspectives.
    - Les r√©ponses doivent √™tre concises et bien structur√©es.

    Voici les 20 derniers √©changes :
    """

    formatted_messages.insert(0, {"role": "system", "content": system_prompt})

    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    try:
        model_name = model_agent_moderator
        model_temperature = 1.0
        response = await client.chat.completions.create(
            model=model_name,
            messages=formatted_messages,
            temperature=model_temperature
        )

        summary_response = response.choices[0].message.content

        if summary_response:
            if isinstance(summary_response, bytes):
                summary_response = summary_response.decode("utf-8")
            
            summary_response = str(summary_response).strip()
            summary_response = html.unescape(summary_response)
            
            # Store the summary in the database
            summary_message = DebateMessageCreate(
                agent_name="synth√©tiseur",
                model_used=model_name,
                temperature=model_temperature,
                content=summary_response,
                is_moderator=True,
                is_final=False
            )
            await crud.async_add_message_to_debate(db, debate_id, summary_message)

            # Broadcast the summary via WebSocket
            await websocket.send_json({
                "type": "summary",
                "agent_name": "synth√©tiseur",
                "model_used": model_name,
                "temperature": model_temperature,
                "content": summary_response,
                "debate_id": debate_id,
                "is_moderator": True,
                "is_final": True,
                "timestamp": datetime.utcnow().isoformat()
            })
            
            return summary_response

    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de la synth√®se : {e}")
        return None

async def generate_final_article(debate_id: int, db: AsyncSession, websocket: WebSocket, history: List[Dict[str, str]]):
    """G√©n√®re un article final de synth√®se structur√© du d√©bat."""
    if len(history) < final_article_based_on_x_messages:
        logger.warning("Pas assez de messages pour g√©n√©rer un article final.")
        return None

    debate = await crud.async_get_debate(db, debate_id)
    if not debate:
        return None
    
    sujet_debat = debate.topic

    acteurs = "\n".join([f"- **{agent.name}** : {agent.context}" for agent in debate.agents])

    # Construire le prompt avec le titre et les acteurs
    article_prompt = f"""
        Tu es un r√©dacteur sp√©cialis√© dans l'analyse des d√©bats complexes. Ton objectif est de produire une synth√®se qui **refl√®te la richesse des √©changes**, en mettant en lumi√®re les **id√©es marquantes**, les tensions intellectuelles, les connexions inattendues et les pistes √©mergentes.

        ### **Titre du sujet** :
        {sujet_debat}  # Titre exact du sujet du d√©bat

        ### **Acteurs du d√©bat** :
        {acteurs}  # Liste des acteurs du d√©bat et leur r√¥le

        ### **Attentes g√©n√©rales**
        *   **Fluidit√©** : La synth√®se doit √™tre naturelle, sans structure fig√©e ni d√©coupage artificiel en sections pr√©d√©finies.
        *   **Adaptabilit√©** : Elle doit s‚Äôajuster √† la dynamique du d√©bat, en mettant en avant les √©l√©ments qui ont le plus marqu√© l‚Äô√©change.
        *   **Coh√©rence** : Le texte doit raconter une **√©volution de la r√©flexion**, sans juxtaposer des avis isol√©s.
        
        ### **Approche**
        1.  **Introduction contextuelle** : Expose **le c≈ìur du sujet**, ce qui l‚Äôa rendu int√©ressant et ce qui √©tait en jeu.
        2.  **Dynamique du d√©bat** : Montre **comment la discussion a √©volu√©**, quels points de tension ou d‚Äôaccord ont √©merg√© naturellement.
        3.  **Pistes et √©volutions** : Mettez en avant les r√©flexions ou id√©es nouvelles qui ont √©merg√© √† travers l‚Äô√©change. 
        4.  **Ouverture** : Conclus en √©largissant la perspective, sans chercher √† "clore" le sujet, mais en invitant √† prolonger la r√©flexion.
            
        ### **Ton & Style**
        *   **Engageant et fluide**, sans rigidit√© acad√©mique. 
        *   **Synth√©tique mais nuanc√©**, en √©vitant les cat√©gories rigides ou les oppositions simplistes.
        *   **Naturel**, avec une progression qui refl√®te celle du d√©bat.
            
        üéØ **Ta mission :** Construire une synth√®se fid√®le √† l‚Äôesprit du d√©bat, qui donne envie de s‚Äôy plonger et d‚Äôen prolonger les r√©flexions.

        ### **Historique du d√©bat** :
        {json.dumps(history, indent=2)}

        ### **Important** : Dans la synth√®se finale, merci d'inclure une **liste des acteurs du d√©bat** √† la fin de l'introduction, ainsi qu'une mention de leur r√¥le ou contribution sp√©cifique. Cette liste doit √™tre mise en avant et facilement identifiable pour les lecteurs.
    """


    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    try:
        model_name = model_agent_moderator
        model_temperature = 1.0
        response = await client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": article_prompt}],
            temperature=model_temperature
        )

        final_article = response.choices[0].message.content

        if final_article:
            final_article = html.unescape(final_article.strip())

            # Enregistrement dans la base de donn√©es
            db.add(DebateMessage(
                debate_id=debate_id, agent_name="synth√®se finale", model_used=model_name,
                temperature=model_temperature, content=final_article, timestamp=datetime.utcnow(),
                is_moderator=True
            ))
            await db.commit()

            # Envoi au WebSocket
            await websocket.send_json({
                "agent_name": "synth√®se finale",
                "model_used": model_name,
                "temperature": model_temperature,
                "content": final_article,
                "debate_id": debate_id,
                "consensus_reached": True,
                "is_moderator": True,
                "is_final": True
            })

            return html.unescape(final_article)

    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de l'article final : {e}")
        return None

async def generate_moderator_prompt(debate_id: int, db: AsyncSession, websocket: WebSocket, history: List[Dict[str, str]]):
    """G√©n√®re une synth√®se IA pour le mod√©rateur."""
    if len(history) < moderator_for_last_x_messages:
        logger.warning("Pas assez de messages pour une synth√®se du Mod√©rateur.")
        return None

    formatted_messages = [
        {"role": "user", "content": f"{msg['agent_name']}: {msg['content']}"}
        for msg in history[-moderator_for_last_x_messages:]
    ]

    system_prompt = """
    Tu es un **mod√©rateur IA** charg√© d'aider un d√©bat √† avancer en synth√©tisant les id√©es r√©centes. 
    üîπ **Objectifs :**
    1. Identifier les **convergences** entre les arguments.
    2. Mettre en lumi√®re les **points de d√©saccords**.
    3. Proposer une **direction commune** pour la suite du d√©bat.

    üîç **Synth√®se interm√©diaire du d√©bat** :
    """

    formatted_messages.insert(0, {"role": "system", "content": system_prompt})

    client = openai.AsyncOpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)

    try:
        model_name = model_agent_moderator
        model_temperature = 0.7

        response = await client.chat.completions.create(
            model=model_name,
            messages=formatted_messages,
            temperature=model_temperature
        )

        moderator_prompt = response.choices[0].message.content.strip()

        if moderator_prompt:
            moderator_prompt = html.unescape(moderator_prompt)

            # Enregistrement en base
            db.add(DebateMessage(
                debate_id=debate_id, agent_name="mod√©rateur ia", model_used=model_name,
                temperature=model_temperature, content=moderator_prompt, timestamp=datetime.utcnow(),
                is_moderator=True
            ))
            await db.commit()

            # Envoi WebSocket
            await websocket.send_json({
                "agent_name": "mod√©rateur ia",
                "model_used": model_name,
                "temperature": model_temperature,
                "content": moderator_prompt,
                "debate_id": debate_id,
                "consensus_reached": False,
                "is_moderator": True,
                "is_final": False
            })
            
            logger.info(f"‚úÖ Mod√©rateur IA envoy√© pour le d√©bat {debate_id}")
            return moderator_prompt

    except Exception as e:
        logger.error(f"Erreur dans generate_moderator_prompt : {e}")
        return None

async def run_discussion(
    debate_id: int, 
    agents: List[DebateAgent], 
    websocket: WebSocket, 
    db: AsyncSession
) -> None:
    """Fait discuter les agents IA en continu en t√¢che de fond."""
    logger.info(f"üöÄ D√©but du d√©bat {debate_id} avec {len(agents)} agents")

    if not agents:
        logger.error(f"‚ùå Aucun agent disponible pour le d√©bat {debate_id}. Arr√™t.")
        return

    # Initialiser l'historique avec les messages existants
    history = []
    past_messages = await crud.async_get_debate_messages(db, debate_id)
    for msg in past_messages:
        history.append({"agent_name": msg.agent_name, "content": msg.content.decode("utf-8") if isinstance(msg.content, bytes) else msg.content})
    logger.info(f"Initial history length: {len(history)}")

    agent_index = 0

    while True:
        try:
            # Rafra√Æchir l'√©tat du d√©bat avant chaque tour
            debate = await crud.async_get_debate(db, debate_id)
            if not debate:
                logger.warning(f"‚èπ D√©bat {debate_id} non trouv√©.")
                break

            if debate.status != DebateStatus.ACTIVE:
                if debate.status == DebateStatus.PAUSED:
                    logger.info(f"‚è∏ D√©bat {debate_id} en pause, attente...")
                    await asyncio.sleep(5)
                    continue
                elif debate.status in [DebateStatus.STOPPED, DebateStatus.TIMEOUT]:
                    logger.info(f"‚èπ D√©bat {debate_id} arr√™t√© ({debate.status.value}).")
                    break

            # Timeout : V√©rifier si le d√©bat est inactif depuis trop longtemps
            timeout = timedelta(seconds=debate.timeout_duration)
            if datetime.utcnow() - debate.last_activity > timeout:
                logger.info(f"‚èπ D√©bat {debate_id} termin√© par timeout apr√®s {debate.timeout_duration} sec d'inactivit√©.")
                debate.status = DebateStatus.TIMEOUT
                await db.commit()
                await websocket.send_json({"type": "debate_timeout", "message": "Debate timed out due to inactivity"})
                break

            # Check message count before proceeding
            message_count = await crud.async_count_debate_messages(db, debate_id)
            if message_count >= end_after_x_messages:
                final_article = await generate_final_article(debate_id, db, websocket, history)
                if final_article:
                    history.append({"agent_name": "Synth√®se Finale", "content": final_article})
                    debate.status = DebateStatus.STOPPED
                    await db.commit()
                    await websocket.send_json({"type": "debate_stopped", "message": "Le d√©bat est termin√©."})
                    logger.info(f"‚úÖ D√©bat {debate_id} stopp√© apr√®s {message_count} messages.")

                    # Generate and send PDF report
                    try:
                        pdf_path = generate_pdf_from_markdown(final_article)
                        if pdf_path:
                            recipient_emails_str = os.getenv("RECIPIENT_EMAILS")
                            recipient_emails = recipient_emails_str.split(",")
                            subject = debate.topic or "AI Debate Report"
                            html_body = markdown.markdown(final_article)

                            send_email(recipient_emails, subject, html_body, pdf_path)
                            logger.info(f"‚úÖ Email with PDF report sent for debate {debate_id}")
                            await websocket.send_json({
                                "type": "email_sent",
                                "message": "Email with PDF report sent successfully.",
                                "debate_id": debate_id
                            })
                        else:
                            logger.error(f"‚ùå Failed to generate PDF for debate {debate_id}")
                            await websocket.send_json({
                                "type": "error",
                                "message": "Failed to generate PDF report.",
                                "debate_id": debate_id
                            })
                    except Exception as e:
                        logger.error(f"‚ùå Error generating or sending PDF: {e}")
                        await websocket.send_json({
                            "type": "error",
                            "message": f"Error generating or sending PDF report: {str(e)}",
                            "debate_id": debate_id
                        })
                break

            # ‚úÖ S√©lection de l'agent suivant
            agent = agents[agent_index]
            logger.info(f"üó£ Tour de {agent.name} ({agent_index}/{len(agents)})")

            # ‚úÖ G√©n√©rer la r√©ponse de l'agent
            response, history = await generate_response(agent, debate_id, history, websocket, db, agents)

            if response:
                debate.last_activity = datetime.utcnow()
                await db.commit()
                logger.info(f"‚úÖ R√©ponse enregistr√©e pour {agent.name}")

                # Update message count after agent response
                message_count = await crud.async_count_debate_messages(db, debate_id)
                logger.info(f"[DEBUG] Counter after agent response: {message_count}")

                # Mod√©rateur intervient apr√®s un certain nombre de messages
                if message_count % moderator_every_x_messages == 0:
                    moderator_prompt = await generate_moderator_prompt(debate_id, db, websocket, history)
                    if moderator_prompt:
                        history.append({"agent_name": "Mod√©rateur IA", "content": moderator_prompt})
                        message_count = await crud.async_count_debate_messages(db, debate_id)
                        logger.info(f"[DEBUG] Counter after moderator: {message_count}")

                # Summarizer intervient √† intervalles r√©guliers
                if message_count % summarize_every_x_messages == 0:
                    summary_response = await generate_summary(debate_id, db, websocket)
                    if summary_response:
                        history.append({"agent_name": "Summarizer", "content": str(summary_response)})
                        message_count = await crud.async_count_debate_messages(db, debate_id)
                        logger.info(f"[DEBUG] Counter after summary: {message_count}")

            else:
                logger.warning(f"‚ö†Ô∏è {agent.name} n'a pas r√©pondu.")

            # ‚úÖ Passer au prochain agent
            agent_index = (agent_index + 1) % len(agents)

            # ‚úÖ Pause avant le prochain tour
            await asyncio.sleep(pause_between_message)

        except Exception as e:
            logger.error(f"‚ùå Erreur dans la boucle principale : {e}")
            await asyncio.sleep(5)
            continue
